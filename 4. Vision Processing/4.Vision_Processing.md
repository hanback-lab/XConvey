# [Vision 처리](<4. 비전처리.md>)
컴퓨터 비전은 인간의 시각 능력을 모방하고 이해하도록 컴퓨터의 로직을 구성하는 것이며, 인공지능의 한 분야로 발전하였습니다. 물론 인공지능 이전에도 영상을 처리하는 분야는 있었지만 인공지능 기술의 발달에 따라, 이전에는 불가능 했던 복잡한 로직의 구현이 가능해졌습니다. 비전 처리는 알고리즘을 구현한 프레임워크와 머신러닝과 딥러닝을 기반으로 하는 모델을 사용하여 디지털 이미지와 비디오를 해석할 수 있으며, 컴퓨터가 객체를 식별하고, 패턴, 나아가서 행동등을 구별할 수 있습니다.
본 장에서는 컴퓨터를 이용한 이미지 처리의 기본적인 도구인 OpenCV와 전처리, 머신러닝과 분류 알고리즘, 머신 러닝기반 분류의 확장을 학습합니다. 


&nbsp;
<img src="image/opencv.png" width=50%>

### OPENCV (Open Source Computer Vision Library)
컴퓨터 비전, 이미지프로세싱 머신러닝의 전반에 사용되는 영상처리 라이브러리 입니다
이미지와 비디오파일 혹은 디지털 데이타의 속성을 조절하는 도구 이며, 얼굴인식, 물체인식 그리고 로보틱스등에서 사용되고 있습니다.

OpenCV에서 사용되는 기능들에는 다음이 있습니다.
-  이미지 및 비디오 프로세싱: OpenCV는 이들의 조작과 분석 그리고 데이터변환등의 기능을 수행하며 컬러변환, edge detection, noise reduction 등의 기능을 제공합니다.
- Computer Vision: Object Detection, face recognition, feature extraction등의 기능을 제공하며, 자율주행차 surveillance system, 증강현실, 이미지 및 비디오 편집등에 사용되고 있습니다.
- 머신러닝과의 결합: 다양한 머신러닝 프레임워크의 학습과 학습데이더등의 작성에 사용되며, 분류 및 물체인식 비디오 분석등의 분야에서 견고한 도구로 사용되고 있습니다.
- 실시간 Performance: OpenCV는 실시간 처리를 위해 디자인 되어있습니다.
소프트웨어 엔지니어로 하여금 문제를 빨리 효율적으로 해결하도록 돕습니다.
- 오픈소스, 크로스 플랫폼: 소스가 오픈되어있으며, 다양한 개발 언어, 다양한 운영체제, 다양한 하드웨어 플랫폼을 지원합니다.

- OpenCV의 예제를 통해 사용방법을 익힙니다.
본 키트의 물체에 점을 찍는 공정을 거친 물체와 일반 물체를 OpenCV를 통해 분류하는 예제입니다.

&nbsp;

```python
import cv2
import numpy as np


cap = cv2.VideoCapture(1)


def hasPointInROI(frame):
    
    imgray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
    ret,thresh = cv2.threshold(imgray, 100, 255,cv2.THRESH_BINARY)
    cimg = cv2.cvtColor(thresh,cv2.COLOR_GRAY2BGR)

    contours,hierarchy = cv2.findContours(thresh,2,1)
    cnt = contours

    for i in range (len(cnt)):
        #발견된 contour에서 원에 가까운 물체를 찾는다. 단 반지름의 길이를 제한한다. 
        (x,y),radius = cv2.minEnclosingCircle(cnt[i])
        center = (int(x),int(y))
        radius = int(radius)
        if(radius < 10 and radius >3 ):
            cv2.circle(frame,center,radius,(0,255,0),2)
        cv2.imshow("check", frame)



def findCircleInROI(img):
    frame = img.copy()
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray_blurred = cv2.blur(gray, (3, 3))
    detected_circles = cv2.HoughCircles(gray_blurred,cv2.HOUGH_GRADIENT,1,50,param1=50,param2=35, minRadius=35,maxRadius=50)

    # 발견된 원을 그린다.
    if detected_circles is not None:

        detected_circles = np.uint16(np.around(detected_circles))

        for pt in detected_circles[0, :]:
            a, b, r = pt[0], pt[1], pt[2]
            cv2.circle(frame, (a, b), r, (0, 255, 0), 2)
            cv2.imshow("Detected Circle", frame)
            cv2.waitKey(1)
            return a,b,r

    return None,None,None




while True:
    
    # Read image.
    _Result, img = cap.read()
    if(_Result != True):

        break

    org = img.copy()
    

    resized = cv2.resize(org, (640,480))
    x, y, r = findCircleInROI(resized)
    if(x is not None and y is not None and r is not None):

        crop_img = org[y-r:y+r, x-r:x+r]
        if(len(crop_img)!=0):
            hasPointInROI(crop_img)
 
    else:
        cv2.waitKey(1)

cv2.destroyAllWindows()
```


### 이미지 전처리

전처리 과정이란 컴퓨터 비전이나 머신러닝 알고리즘을 사용하기 위해 이미지나 동영상을 분석하거나 준비하는 과정입니다. 이미지 품질을 향상시키거나 관계성 있는 정보를 획득하고, 다른 연산처리에 사용되도록 최적화 되는 과정입니다.

이미지 전처리의 예는는 다음과 같습니다.
- 이미지 품질을 향상: 이미지 크기를 변경시키고, 노이즈를 제거하거나, 반사광을 줄이고, 변형을 시키거나 회복시키고, 명암을 조절할 수 있습니다.
- 이미지 표준화: 이미지 사이즈의 통일, 해상도 컬러스페이스의 조절
- Feature Extraction : 연관있는 이미지의 정보들을 분석할 수 있습니다.
- 모델 학습 : 머신러닝학습에 필요한 형태로 이미지를 준비할 수 있습니다. 


#### 예제 코드

1. 이미지 크기 조절

<원본>
<img src="image/lena.png" width=100%>


``` python

import cv2

img = cv2.imread("lena.png")
resized = cv2.resize(img, (320,240))
cv2.imshow("resized", resized)
cv2.wait(0)

cv2.destroyAllWindows()
```
<크기변환>

<img src="image/resized_lena.png" width=50%>

2. 반사광 조절

```python


import cv2
import numpy as np

class HomomorphicFilter:

    def __init__(self, a = 0.5, b = 1.5):
        self.a = float(a)
        self.b = float(b)

    # Filters
    def __butterworth_filter(self, I_shape, filter_params):
        P = I_shape[0]/2
        Q = I_shape[1]/2
        U, V = np.meshgrid(range(I_shape[0]), range(I_shape[1]), sparse=False, indexing='ij')
        Duv = (((U-P)**2+(V-Q)**2)).astype(float)
        H = 1/(1+(Duv/filter_params[0]**2)**filter_params[1])
        return (1 - H)

    def __gaussian_filter(self, I_shape, filter_params):
        P = I_shape[0]/2
        Q = I_shape[1]/2
        H = np.zeros(I_shape)
        U, V = np.meshgrid(range(I_shape[0]), range(I_shape[1]), sparse=False, indexing='ij')
        Duv = (((U-P)**2+(V-Q)**2)).astype(float)
        H = np.exp((-Duv/(2*(filter_params[0])**2)))
        return (1 - H)

    # Methods
    def __apply_filter(self, I, H):
        H = np.fft.fftshift(H)
        I_filtered = (self.a + self.b*H)*I
        return I_filtered

    def filter(self, I, filter_params, filter='butterworth', H = None):
        
        if len(I.shape) is not 2:
            raise Exception('Improper image')
        
        I_log = np.log1p(np.array(I, dtype="float"))
        I_fft = np.fft.fft2(I_log)

        # Filters
        if filter=='butterworth':
            H = self.__butterworth_filter(I_shape = I_fft.shape, filter_params = filter_params)
        elif filter=='gaussian':
            H = self.__gaussian_filter(I_shape = I_fft.shape, filter_params = filter_params)
        elif filter=='external':
            print('external')
            if len(H.shape) is not 2:
                raise Exception('Invalid external filter')
        else:
            raise Exception('Selected filter not implemented')
        
        # Apply filter on frequency domain then take the image back to spatial domain
        I_fft_filt = self.__apply_filter(I = I_fft, H = H)
        I_filt = np.fft.ifft2(I_fft_filt)
        I = np.exp(np.real(I_filt))-1
        return np.uint8(I)

output_images = []

imgColor = cv2.imread("lena.png")
gray = cv2.cvtColor(imgColor, cv2.COLOR_BGR2GRAY)
homo_filter = HomomorphicFilter(a = 0.75, b = 1.25)
img_filtered = homo_filter.filter(I=gray, filter_params=[30,2])

output_images.append(gray)
output_images.append(img_filtered)
concat_image = np.hstack((output_images))
cv2.imshow("homo", concat_image)
cv2.waitKey(0)
cv2.destroyAllWindows()

```
<반사광 조절>

<img src="image/homo.png" width=50%>

&nbsp;

*[연습문제]: 레나의 얼굴부분만을 확대한 이미지를 생성해봅니다.


## [머신러닝]()

&nbsp;

<img src="image/AI.png" width=70%>

&nbsp;


Machine Learning(ML) 이란 인공지능의 한 분야로서 컴퓨터가 명시적으로 프로그램되지 하지 않고 학습하게 하는 것입니다. 데이터를 분석하는 알고리즘, 예측이나 결정을 하며, 보다 많은 알고리즘에 노출될 수록 일을 더 잘할 수 있게 됩니다.
기존의 프로그래밍과 다르게 컴퓨터는 명령을 받지 않고 데이터로부터 학습되도록 합니다.  딥러닝은 머신러닝의 한 분야로 인공신경망을 사용하는 인공지능이며, 복잡한 feature들과 pattern을 data로부터 얻고 여러 층의 레이어를 구성하여 이들간의 복잡한 데이터 패턴을 학습합니다.

본 키트의 물체에 점을 찍는 공정을 거친 물체와 일반 물체를 YOLOv8 을 통해 분류하는 예제입니다.
Dataset은 https://github.com/hanback-lab/XConvey/src/yolo_data 에서 다운받을 수 있습니다.
```python
# Train Script
import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'
from multiprocessing import Process, freeze_support
from ultralytics import YOLO
import onnx
import locale
locale.getpreferredencoding = lambda: "UTF-8"


def train():
    model = YOLO('yolov8n.pt')
    results = model.train(data='datasets/data.yaml', epochs=120, imgsz=320)
    #자동으로 runs 폴더 밑에 weight 폴더가 생성되고 그 및에 학습된 파일이 생성된다.

if __name__ == '__main__':
    freeze_support()
    train()
``` 

```python
# Predict Script
import cv2
import matplotlib.pyplot as plt

def imread(path):
    return cv2.imread(path)

def imwrite(img, path):
    if cv2.imwrite(path, img):
        print('Image saved to "{}"'.format(path))
    else:
        print('Failed to save image to "{}"'.format(path))

def imshow(img, figsize=(10, 10), is_bgr=True):
    if is_bgr:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=figsize)
    plt.imshow(img, cmap='gray')
    plt.show()

import ultralytics

ultralytics.checks()
from ultralytics import YOLO
model = YOLO('runs/detect/train/weights/best.pt')



cap = cv2.VideoCapture(0)
while (True):
    success,frame = cap.read()
    if not success:
        break
    frame = cv2.resize(frame,(0,0),fx=1.5,fy=1.5)
    result = model.predict(frame,verbose=False)
    result = result[0].plot()
    print("result", result)
    cv2.imshow('yolo',result)
    if cv2.waitKey(1)& 0xFF == 27:    
        break
        
cap.release()
cv2.destroyAllWindows()

```
